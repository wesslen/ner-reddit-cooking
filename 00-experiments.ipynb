{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4393db05",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "### 1. Develop Model v1.0 using GPT3.5 zeroshot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9adbd58c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created unstructured dataset 'hmwk_1_zeroshot' in database SQLite\u001b[0m\n",
            "\u001b[38;5;2m✔ Imported 500 annotated examples and saved them to 'hmwk_1_zeroshot'\n",
            "(session 2024-02-05_13-38-41) in database SQLite\u001b[0m\n",
            "Found and keeping existing \"answer\" in 0 examples\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy db-in hmwk_1_zeroshot data/gpt3-5-zeroshot.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "290de66e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2024-02-05 13:38:42,973] [INFO] Set up nlp object from config\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 400 | Evaluation: 100 (20% split)\n",
            "Training: 400 | Evaluation: 100\n",
            "Labels: ner (3)\n",
            "[2024-02-05 13:38:43,017] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2024-02-05 13:38:43,019] [INFO] Created vocabulary\n",
            "[2024-02-05 13:38:43,019] [INFO] Finished initializing nlp object\n",
            "[2024-02-05 13:38:43,730] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 400 | Evaluation: 100 (20% split)\n",
            "Training: 400 | Evaluation: 100\n",
            "Labels: ner (3)\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     34.21    0.00    0.00    0.00    0.00\n",
            "  1     200        277.34   3013.31   19.90   28.37   15.33    0.20\n",
            "  2     400       1760.56   2475.35   23.61   29.82   19.54    0.24\n",
            "  4     600        211.06   2190.97   28.45   32.51   25.29    0.28\n",
            "  5     800        628.07   1820.25   36.06   39.81   32.95    0.36\n",
            "  8    1000        475.87   1566.02   30.27   42.96   23.37    0.30\n",
            " 10    1200        624.23   1135.61   31.97   36.63   28.35    0.32\n",
            " 13    1400        625.82    826.32   31.25   34.25   28.74    0.31\n",
            " 17    1600        734.03    640.05   31.78   43.92   24.90    0.32\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/experiment-1/model-last\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P       R       F\n",
            "INGREDIENT   50.91   38.36   43.75\n",
            "DISH         29.73   30.56   30.14\n",
            "EQUIPMENT    25.00   18.60   21.33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train --ner hmwk_1_zeroshot ./output/experiment-1 --label-stats --training.patience=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "88aa7ab1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Train curve diagnostic ===========================\u001b[0m\n",
            "Training 4 times with 25%, 50%, 75%, 100% of the data\n",
            "\n",
            "%      Score    ner   \n",
            "----   ------   ------\n",
            "  0%   0.00     0.00  \n",
            " 25%   0.26 ▲   0.26 ▲\n",
            " 50%   0.29 ▲   0.29 ▲\n",
            " 75%   0.29 ▲   0.29 ▲\n",
            "100%   0.36 ▲   0.36 ▲\n",
            "\n",
            "\u001b[38;5;2m✔ Accuracy improved in the last sample\u001b[0m\n",
            "As a rule of thumb, if accuracy increases in the last segment, this could\n",
            "indicate that collecting more annotations of the same type will improve the\n",
            "model further.\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train-curve --ner hmwk_1_zeroshot --training.patience=800"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f945f3d",
      "metadata": {},
      "source": [
        "### 2. Create evaluation dataset (200 unlabeled), retrain on `hmwk-1-zeroshot` and eval on `hmwk-1-eval`\n",
        "\n",
        "For this, I used a different data 200 data. So in your case you may use `ner.manual` or `ner.correct`, but in my case I only needed to load the data like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a1c28883",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created unstructured dataset 'hmwk_1_eval' in database SQLite\u001b[0m\n",
            "\u001b[38;5;2m✔ Imported 200 annotated examples and saved them to 'hmwk_1_eval'\n",
            "(session 2024-02-05_13-46-45) in database SQLite\u001b[0m\n",
            "Found and keeping existing \"answer\" in 200 examples\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy db-in hmwk_1_eval data/eval-reddit.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2880d4b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2024-02-05 13:46:46,517] [INFO] Set up nlp object from config\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 500 | Evaluation: 200 (from datasets)\n",
            "Training: 500 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "[2024-02-05 13:46:46,601] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2024-02-05 13:46:46,603] [INFO] Created vocabulary\n",
            "[2024-02-05 13:46:46,603] [INFO] Finished initializing nlp object\n",
            "[2024-02-05 13:46:47,301] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 500 | Evaluation: 200 (from datasets)\n",
            "Training: 500 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     48.64    0.00    0.00    0.00    0.00\n",
            "  0     200        221.41   3556.27    3.78  100.00    1.93    0.04\n",
            "  1     400        108.75   2187.82   31.97   43.15   25.39    0.32\n",
            "  3     600        977.52   2738.36   33.23   41.98   27.50    0.33\n",
            "  4     800        412.58   2150.96   39.68   40.33   39.05    0.40\n",
            "  6    1000        472.20   1839.57   41.99   46.40   38.35    0.42\n",
            "  8    1200        537.61   1528.54   35.95   40.94   32.05    0.36\n",
            " 11    1400        562.62   1158.31   38.77   46.78   33.10    0.39\n",
            " 14    1600        674.13    772.69   34.09   41.19   29.07    0.34\n",
            " 17    1800        798.67    779.94   35.59   41.15   31.35    0.36\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/experiment-2/model-last\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P       R       F\n",
            "INGREDIENT   55.52   45.83   50.21\n",
            "EQUIPMENT    40.00   21.33   27.83\n",
            "DISH         23.48   24.11   23.79\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train --ner hmwk_1_zeroshot,eval:hmwk_1_eval ./output/experiment-2  --label-stats --training.patience=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ef2dd7ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Train curve diagnostic ===========================\u001b[0m\n",
            "Training 4 times with 25%, 50%, 75%, 100% of the data\n",
            "\n",
            "%      Score    ner   \n",
            "----   ------   ------\n",
            "  0%   0.00     0.00  \n",
            " 25%   0.31 ▲   0.31 ▲\n",
            " 50%   0.35 ▲   0.35 ▲\n",
            " 75%   0.38 ▲   0.38 ▲\n",
            "100%   0.42 ▲   0.42 ▲\n",
            "\n",
            "\u001b[38;5;2m✔ Accuracy improved in the last sample\u001b[0m\n",
            "As a rule of thumb, if accuracy increases in the last segment, this could\n",
            "indicate that collecting more annotations of the same type will improve the\n",
            "model further.\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train-curve --ner hmwk_1_zeroshot,eval:hmwk_1_eval --training.patience=800"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc25491",
      "metadata": {},
      "source": [
        "\n",
        "### 3. Add Workshop Data as training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5d447704",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created unstructured dataset 'hmwk_1_workshop' in database SQLite\u001b[0m\n",
            "\u001b[38;5;2m✔ Imported 1250 annotated examples and saved them to 'hmwk_1_workshop'\n",
            "(session 2024-02-05_13-55-35) in database SQLite\u001b[0m\n",
            "Found and keeping existing \"answer\" in 1250 examples\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy db-in hmwk_1_workshop data/pydata-nyc-2023.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f52451cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created dataset 'hmwk_1_train_exp3'\u001b[0m\n",
            "\u001b[38;5;2m✔ Merged 1750 examples from 2 datasets\u001b[0m\n",
            "Created merged dataset 'hmwk_1_train_exp3'\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy db-merge hmwk_1_zeroshot,hmwk_1_workshop hmwk_1_train_exp3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "85e22838",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2024-02-05 13:55:38,503] [INFO] Set up nlp object from config\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 1683 | Evaluation: 200 (from datasets)\n",
            "Training: 1577 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "[2024-02-05 13:55:38,669] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2024-02-05 13:55:38,671] [INFO] Created vocabulary\n",
            "[2024-02-05 13:55:38,671] [INFO] Finished initializing nlp object\n",
            "[2024-02-05 13:55:40,177] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 1683 | Evaluation: 200 (from datasets)\n",
            "Training: 1577 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     39.86    0.00    0.00    0.00    0.00\n",
            "  0     200        137.25   3400.32   34.52   62.67   23.82    0.35\n",
            "  0     400         92.80   2141.72   39.60   54.27   31.17    0.40\n",
            "  1     600        144.72   2777.94   53.10   58.40   48.69    0.53\n",
            "  1     800        196.77   2702.21   53.26   54.38   52.19    0.53\n",
            "  2    1000        374.01   2876.58   54.10   58.57   50.26    0.54\n",
            "  2    1200        374.63   2963.83   53.38   54.25   52.54    0.53\n",
            "  3    1400        486.09   3367.86   51.78   55.51   48.51    0.52\n",
            "  4    1600        656.64   3237.36   57.65   58.59   56.74    0.58\n",
            "  5    1800        762.39   3373.22   57.19   56.60   57.79    0.57\n",
            "  7    2000       1074.89   3599.61   56.28   57.25   55.34    0.56\n",
            "  9    2200       1288.18   3482.08   50.61   54.92   46.94    0.51\n",
            " 11    2400       1633.68   3209.38   58.60   60.98   56.39    0.59\n",
            " 13    2600       1822.72   2810.99   57.99   57.49   58.49    0.58\n",
            " 16    2800       1711.26   2189.65   53.95   54.14   53.77    0.54\n",
            " 18    3000       1819.85   1945.96   53.37   54.04   52.71    0.53\n",
            " 21    3200       1899.14   1791.75   51.83   55.87   48.34    0.52\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/experiment-3/model-last\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P       R       F\n",
            "INGREDIENT   65.86   63.80   64.81\n",
            "DISH         44.86   42.86   43.84\n",
            "EQUIPMENT    59.18   38.67   46.77\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train --ner hmwk_1_train_exp3,eval:hmwk_1_eval ./output/experiment-3 --label-stats --training.patience=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b62101c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Train curve diagnostic ===========================\u001b[0m\n",
            "Training 4 times with 25%, 50%, 75%, 100% of the data\n",
            "\n",
            "%      Score    ner   \n",
            "----   ------   ------\n",
            "  0%   0.00     0.00  \n",
            " 25%   0.39 ▲   0.39 ▲\n",
            " 50%   0.48 ▲   0.48 ▲\n",
            " 75%   0.53 ▲   0.53 ▲\n",
            "100%   0.59 ▲   0.59 ▲\n",
            "\n",
            "\u001b[38;5;2m✔ Accuracy improved in the last sample\u001b[0m\n",
            "As a rule of thumb, if accuracy increases in the last segment, this could\n",
            "indicate that collecting more annotations of the same type will improve the\n",
            "model further.\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train-curve --ner hmwk_1_train_exp3,eval:hmwk_1_eval --training.patience=800"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d9011e2",
      "metadata": {},
      "source": [
        "### 4. Correct workshop data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3afd65ac",
      "metadata": {},
      "source": [
        "I've commented out below because I previously saved this step as `data/hmwk-1-review.jsonl`. This allows me to fully rerun the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "cc62896d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python -m prodigy ner.model-annotate hmwk_1_workshop_model ./output/experiment-2/model-best data/pydata-nyc-2023.jsonl ner_v2\n",
        "# !python -m prodigy review hmwk_1_review hmwk_1_workshop,hmwk_1_workshop_model --label DISH,EQUIPMENT,INGREDIENT --auto-accept\n",
        "# !python -m prodigy db-out hmwk_1_review > data/hmwk-1-review.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9bede1d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Imported 199 annotated examples and saved them to 'hmwk_1_review'\n",
            "(session 2024-02-05_14-12-29) in database SQLite\u001b[0m\n",
            "Found and keeping existing \"answer\" in 199 examples\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy db-in hmwk_1_review data/hmwk-1-review.jsonl "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "52cf80e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created dataset 'hmwk_1_train_exp4'\u001b[0m\n",
            "\u001b[38;5;2m✔ Merged 1097 examples from 2 datasets\u001b[0m\n",
            "Created merged dataset 'hmwk_1_train_exp4'\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy db-merge hmwk_1_zeroshot,hmwk_1_review hmwk_1_train_exp4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "91b5ec26",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2024-02-05 14:12:32,037] [INFO] Set up nlp object from config\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 1097 | Evaluation: 200 (from datasets)\n",
            "Training: 699 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "[2024-02-05 14:12:32,217] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2024-02-05 14:12:32,219] [INFO] Created vocabulary\n",
            "[2024-02-05 14:12:32,219] [INFO] Finished initializing nlp object\n",
            "[2024-02-05 14:12:33,041] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 1097 | Evaluation: 200 (from datasets)\n",
            "Training: 699 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     44.43    0.00    0.00    0.00    0.00\n",
            "  0     200        325.16   3360.95   26.44   49.52   18.04    0.26\n",
            "  1     400        144.53   2368.08   15.12   44.44    9.11    0.15\n",
            "  2     600        177.04   2431.50   29.36   42.52   22.42    0.29\n",
            "  3     800        274.08   2365.64   38.48   43.49   34.50    0.38\n",
            "  4    1000        449.36   2500.00   44.90   53.79   38.53    0.45\n",
            "  6    1200        578.61   2007.99   37.14   44.50   31.87    0.37\n",
            "  8    1400        714.60   1901.71   42.94   45.74   40.46    0.43\n",
            " 10    1600        824.28   1741.53   43.33   45.97   40.98    0.43\n",
            " 13    1800        926.28   1236.59   38.40   44.76   33.63    0.38\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/experiment-4/model-last\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P       R       F\n",
            "INGREDIENT   67.77   42.71   52.40\n",
            "EQUIPMENT    38.82   44.00   41.25\n",
            "DISH         28.05   20.54   23.71\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train --ner hmwk_1_train_exp4,eval:hmwk_1_eval ./output/experiment-4 --label-stats --training.patience=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "802e33a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Train curve diagnostic ===========================\u001b[0m\n",
            "Training 4 times with 25%, 50%, 75%, 100% of the data\n",
            "\n",
            "%      Score    ner   \n",
            "----   ------   ------\n",
            "  0%   0.01     0.01  \n",
            " 25%   0.35 ▲   0.35 ▲\n",
            " 50%   0.41 ▲   0.41 ▲\n",
            " 75%   0.45 ▲   0.45 ▲\n",
            "100%   0.45     0.45  \n",
            "\n",
            "\u001b[38;5;3m⚠ Accuracy stayed the same in the last sample\u001b[0m\n",
            "As a rule of thumb, if accuracy increases in the last segment, this could\n",
            "indicate that collecting more annotations of the same type will improve the\n",
            "model further.\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train-curve --ner hmwk_1_train_exp4,eval:hmwk_1_eval --training.patience=800"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5406e191",
      "metadata": {},
      "source": [
        "### 5. Modify Word Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf9a7e2",
      "metadata": {},
      "source": [
        "We're going to follow [Prodigy docs](https://prodi.gy/docs/named-entity-recognition#transfer-learning) to improve the model by using word vectors (embeddings). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "eb7a59f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "409c1659",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "========================= Generating Prodigy config =========================\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
            "\u001b[38;5;4mℹ Using config from base model\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2024-02-05 14:27:08,313] [INFO] Set up nlp object from config\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 1683 | Evaluation: 200 (from datasets)\n",
            "Training: 1577 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "[2024-02-05 14:27:08,500] [INFO] Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
            "[2024-02-05 14:27:08,500] [INFO] Resuming training for: ['ner', 'tok2vec']\n",
            "[2024-02-05 14:27:08,504] [INFO] Created vocabulary\n",
            "[2024-02-05 14:27:09,456] [INFO] Added vectors: en_core_web_lg\n",
            "[2024-02-05 14:27:10,155] [INFO] Finished initializing nlp object\n",
            "[2024-02-05 14:27:10,155] [INFO] Initialized pipeline components: []\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "Components: ner\n",
            "Merging training and evaluation data for 1 components\n",
            "  - [ner] Training: 1683 | Evaluation: 200 (from datasets)\n",
            "Training: 1577 | Evaluation: 200\n",
            "Labels: ner (3)\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler',\n",
            "'lemmatizer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Frozen components: ['tagger', 'parser', 'attribute_ruler',\n",
            "'lemmatizer']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SPEED   SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------  ------\n",
            "  0       0          0.00     12.94    0.00    0.00    0.00  3478.43    0.00\n",
            "  2    1000          0.00  12615.27   66.37   66.73   66.02  3651.64    0.66\n",
            "  7    2000          0.00  17966.74   64.73   63.32   66.20  3483.35    0.65\n",
            " 18    3000          0.00  19839.04   62.22   61.58   62.87  3533.71    0.62\n",
            " 31    4000          0.00   9043.14   61.48   61.32   61.65  3636.89    0.61\n",
            " 43    5000          0.00   5600.49   59.45   59.72   59.19  3512.89    0.59\n",
            " 56    6000          0.00   3956.27   58.63   58.08   59.19  3546.34    0.59\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/experiment-5/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m prodigy train --ner hmwk_1_train_exp3,eval:hmwk_1_eval ./output/experiment-5 --base-model en_core_web_lg --label-stats"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87dae9fb",
      "metadata": {},
      "source": [
        "### Save models as wheel files\n",
        "\n",
        "As an alternative to zip files, I'll save the models as wheel files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "1340b62b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Building package artifacts: wheel\u001b[0m\n",
            "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
            "output/experiment-1/model-best/meta.json\n",
            "\u001b[38;5;2m✔ Generated README.md from meta.json\u001b[0m\n",
            "\u001b[38;5;2m✔ Successfully created package directory\n",
            "'en_ner_reddit_cooking-1.0.0'\u001b[0m\n",
            "packages/en_ner_reddit_cooking-1.0.0\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/en_ner_reddit_cooking\n",
            "copying en_ner_reddit_cooking/__init__.py -> build/lib/en_ner_reddit_cooking\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tokenizer -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/config.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/README.md -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/meta.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/moves -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/vectors -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/lookups.bin -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/strings.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/key2row -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/vectors.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/meta.json -> build/lib/en_ner_reddit_cooking\n",
            "/Users/ryan/Desktop/Desktop - Ryan’s iMac/teaching/dsba6188-homework-1/venv/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "installing to build/bdist.macosx-13-arm64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.macosx-13-arm64\n",
            "creating build/bdist.macosx-13-arm64/wheel\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/moves -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tokenizer -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/vectors -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/lookups.bin -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/strings.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/key2row -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/vectors.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/config.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/README.md -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/__init__.py -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "copying build/lib/en_ner_reddit_cooking/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating en_ner_reddit_cooking.egg-info\n",
            "writing en_ner_reddit_cooking.egg-info/PKG-INFO\n",
            "writing dependency_links to en_ner_reddit_cooking.egg-info/dependency_links.txt\n",
            "writing entry points to en_ner_reddit_cooking.egg-info/entry_points.txt\n",
            "writing requirements to en_ner_reddit_cooking.egg-info/requires.txt\n",
            "writing top-level names to en_ner_reddit_cooking.egg-info/top_level.txt\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching 'LICENSES_SOURCES'\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "Copying en_ner_reddit_cooking.egg-info to build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-1.0.0-py3.9.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-1.0.0.dist-info/WHEEL\n",
            "creating 'dist/en_ner_reddit_cooking-1.0.0-py3-none-any.whl' and adding 'build/bdist.macosx-13-arm64/wheel' to it\n",
            "adding 'en_ner_reddit_cooking/__init__.py'\n",
            "adding 'en_ner_reddit_cooking/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/README.md'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/config.cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tokenizer'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/ner/moves'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/tok2vec/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/key2row'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/lookups.bin'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/strings.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/vectors'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-1.0.0/vocab/vectors.cfg'\n",
            "adding 'en_ner_reddit_cooking-1.0.0.dist-info/METADATA'\n",
            "adding 'en_ner_reddit_cooking-1.0.0.dist-info/WHEEL'\n",
            "adding 'en_ner_reddit_cooking-1.0.0.dist-info/entry_points.txt'\n",
            "adding 'en_ner_reddit_cooking-1.0.0.dist-info/top_level.txt'\n",
            "adding 'en_ner_reddit_cooking-1.0.0.dist-info/RECORD'\n",
            "removing build/bdist.macosx-13-arm64/wheel\n",
            "\u001b[38;5;2m✔ Successfully created binary wheel\u001b[0m\n",
            "packages/en_ner_reddit_cooking-1.0.0/dist/en_ner_reddit_cooking-1.0.0-py3-none-any.whl\n",
            "\u001b[38;5;4mℹ Building package artifacts: wheel\u001b[0m\n",
            "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
            "output/experiment-2/model-best/meta.json\n",
            "\u001b[38;5;2m✔ Generated README.md from meta.json\u001b[0m\n",
            "\u001b[38;5;2m✔ Successfully created package directory\n",
            "'en_ner_reddit_cooking-2.0.0'\u001b[0m\n",
            "packages/en_ner_reddit_cooking-2.0.0\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/en_ner_reddit_cooking\n",
            "copying en_ner_reddit_cooking/__init__.py -> build/lib/en_ner_reddit_cooking\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tokenizer -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/config.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/README.md -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/meta.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/moves -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/vectors -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/lookups.bin -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/strings.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/key2row -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/vectors.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/meta.json -> build/lib/en_ner_reddit_cooking\n",
            "/Users/ryan/Desktop/Desktop - Ryan’s iMac/teaching/dsba6188-homework-1/venv/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "installing to build/bdist.macosx-13-arm64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.macosx-13-arm64\n",
            "creating build/bdist.macosx-13-arm64/wheel\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/moves -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tokenizer -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/vectors -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/lookups.bin -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/strings.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/key2row -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/vectors.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/config.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/README.md -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/__init__.py -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "copying build/lib/en_ner_reddit_cooking/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating en_ner_reddit_cooking.egg-info\n",
            "writing en_ner_reddit_cooking.egg-info/PKG-INFO\n",
            "writing dependency_links to en_ner_reddit_cooking.egg-info/dependency_links.txt\n",
            "writing entry points to en_ner_reddit_cooking.egg-info/entry_points.txt\n",
            "writing requirements to en_ner_reddit_cooking.egg-info/requires.txt\n",
            "writing top-level names to en_ner_reddit_cooking.egg-info/top_level.txt\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching 'LICENSES_SOURCES'\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "Copying en_ner_reddit_cooking.egg-info to build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-2.0.0-py3.9.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-2.0.0.dist-info/WHEEL\n",
            "creating 'dist/en_ner_reddit_cooking-2.0.0-py3-none-any.whl' and adding 'build/bdist.macosx-13-arm64/wheel' to it\n",
            "adding 'en_ner_reddit_cooking/__init__.py'\n",
            "adding 'en_ner_reddit_cooking/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/README.md'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/config.cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tokenizer'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/ner/moves'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/tok2vec/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/key2row'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/lookups.bin'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/strings.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/vectors'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-2.0.0/vocab/vectors.cfg'\n",
            "adding 'en_ner_reddit_cooking-2.0.0.dist-info/METADATA'\n",
            "adding 'en_ner_reddit_cooking-2.0.0.dist-info/WHEEL'\n",
            "adding 'en_ner_reddit_cooking-2.0.0.dist-info/entry_points.txt'\n",
            "adding 'en_ner_reddit_cooking-2.0.0.dist-info/top_level.txt'\n",
            "adding 'en_ner_reddit_cooking-2.0.0.dist-info/RECORD'\n",
            "removing build/bdist.macosx-13-arm64/wheel\n",
            "\u001b[38;5;2m✔ Successfully created binary wheel\u001b[0m\n",
            "packages/en_ner_reddit_cooking-2.0.0/dist/en_ner_reddit_cooking-2.0.0-py3-none-any.whl\n",
            "\u001b[38;5;4mℹ Building package artifacts: wheel\u001b[0m\n",
            "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
            "output/experiment-3/model-best/meta.json\n",
            "\u001b[38;5;2m✔ Generated README.md from meta.json\u001b[0m\n",
            "\u001b[38;5;2m✔ Successfully created package directory\n",
            "'en_ner_reddit_cooking-3.0.0'\u001b[0m\n",
            "packages/en_ner_reddit_cooking-3.0.0\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/en_ner_reddit_cooking\n",
            "copying en_ner_reddit_cooking/__init__.py -> build/lib/en_ner_reddit_cooking\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tokenizer -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/config.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/README.md -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/meta.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/moves -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/vectors -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/lookups.bin -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/strings.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/key2row -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/vectors.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/meta.json -> build/lib/en_ner_reddit_cooking\n",
            "/Users/ryan/Desktop/Desktop - Ryan’s iMac/teaching/dsba6188-homework-1/venv/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "installing to build/bdist.macosx-13-arm64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.macosx-13-arm64\n",
            "creating build/bdist.macosx-13-arm64/wheel\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/moves -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tokenizer -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/vectors -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/lookups.bin -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/strings.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/key2row -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/vectors.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/config.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/README.md -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/__init__.py -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "copying build/lib/en_ner_reddit_cooking/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating en_ner_reddit_cooking.egg-info\n",
            "writing en_ner_reddit_cooking.egg-info/PKG-INFO\n",
            "writing dependency_links to en_ner_reddit_cooking.egg-info/dependency_links.txt\n",
            "writing entry points to en_ner_reddit_cooking.egg-info/entry_points.txt\n",
            "writing requirements to en_ner_reddit_cooking.egg-info/requires.txt\n",
            "writing top-level names to en_ner_reddit_cooking.egg-info/top_level.txt\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching 'LICENSES_SOURCES'\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "Copying en_ner_reddit_cooking.egg-info to build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-3.0.0-py3.9.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-3.0.0.dist-info/WHEEL\n",
            "creating 'dist/en_ner_reddit_cooking-3.0.0-py3-none-any.whl' and adding 'build/bdist.macosx-13-arm64/wheel' to it\n",
            "adding 'en_ner_reddit_cooking/__init__.py'\n",
            "adding 'en_ner_reddit_cooking/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/README.md'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/config.cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tokenizer'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/ner/moves'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/tok2vec/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/key2row'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/lookups.bin'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/strings.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/vectors'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-3.0.0/vocab/vectors.cfg'\n",
            "adding 'en_ner_reddit_cooking-3.0.0.dist-info/METADATA'\n",
            "adding 'en_ner_reddit_cooking-3.0.0.dist-info/WHEEL'\n",
            "adding 'en_ner_reddit_cooking-3.0.0.dist-info/entry_points.txt'\n",
            "adding 'en_ner_reddit_cooking-3.0.0.dist-info/top_level.txt'\n",
            "adding 'en_ner_reddit_cooking-3.0.0.dist-info/RECORD'\n",
            "removing build/bdist.macosx-13-arm64/wheel\n",
            "\u001b[38;5;2m✔ Successfully created binary wheel\u001b[0m\n",
            "packages/en_ner_reddit_cooking-3.0.0/dist/en_ner_reddit_cooking-3.0.0-py3-none-any.whl\n",
            "\u001b[38;5;4mℹ Building package artifacts: wheel\u001b[0m\n",
            "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
            "output/experiment-4/model-best/meta.json\n",
            "\u001b[38;5;2m✔ Generated README.md from meta.json\u001b[0m\n",
            "\u001b[38;5;2m✔ Successfully created package directory\n",
            "'en_ner_reddit_cooking-4.0.0'\u001b[0m\n",
            "packages/en_ner_reddit_cooking-4.0.0\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/en_ner_reddit_cooking\n",
            "copying en_ner_reddit_cooking/__init__.py -> build/lib/en_ner_reddit_cooking\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tokenizer -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/config.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/README.md -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/meta.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/moves -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/vectors -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/lookups.bin -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/strings.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/key2row -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/vectors.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/meta.json -> build/lib/en_ner_reddit_cooking\n",
            "/Users/ryan/Desktop/Desktop - Ryan’s iMac/teaching/dsba6188-homework-1/venv/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "installing to build/bdist.macosx-13-arm64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.macosx-13-arm64\n",
            "creating build/bdist.macosx-13-arm64/wheel\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/moves -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tokenizer -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/vectors -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/lookups.bin -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/strings.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/key2row -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/vectors.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/config.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/README.md -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/__init__.py -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "copying build/lib/en_ner_reddit_cooking/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating en_ner_reddit_cooking.egg-info\n",
            "writing en_ner_reddit_cooking.egg-info/PKG-INFO\n",
            "writing dependency_links to en_ner_reddit_cooking.egg-info/dependency_links.txt\n",
            "writing entry points to en_ner_reddit_cooking.egg-info/entry_points.txt\n",
            "writing requirements to en_ner_reddit_cooking.egg-info/requires.txt\n",
            "writing top-level names to en_ner_reddit_cooking.egg-info/top_level.txt\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching 'LICENSES_SOURCES'\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "Copying en_ner_reddit_cooking.egg-info to build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-4.0.0-py3.9.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-4.0.0.dist-info/WHEEL\n",
            "creating 'dist/en_ner_reddit_cooking-4.0.0-py3-none-any.whl' and adding 'build/bdist.macosx-13-arm64/wheel' to it\n",
            "adding 'en_ner_reddit_cooking/__init__.py'\n",
            "adding 'en_ner_reddit_cooking/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/README.md'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/config.cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tokenizer'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/ner/moves'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/tok2vec/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/key2row'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/lookups.bin'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/strings.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/vectors'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-4.0.0/vocab/vectors.cfg'\n",
            "adding 'en_ner_reddit_cooking-4.0.0.dist-info/METADATA'\n",
            "adding 'en_ner_reddit_cooking-4.0.0.dist-info/WHEEL'\n",
            "adding 'en_ner_reddit_cooking-4.0.0.dist-info/entry_points.txt'\n",
            "adding 'en_ner_reddit_cooking-4.0.0.dist-info/top_level.txt'\n",
            "adding 'en_ner_reddit_cooking-4.0.0.dist-info/RECORD'\n",
            "removing build/bdist.macosx-13-arm64/wheel\n",
            "\u001b[38;5;2m✔ Successfully created binary wheel\u001b[0m\n",
            "packages/en_ner_reddit_cooking-4.0.0/dist/en_ner_reddit_cooking-4.0.0-py3-none-any.whl\n",
            "\u001b[38;5;4mℹ Building package artifacts: wheel\u001b[0m\n",
            "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
            "output/experiment-5/model-best/meta.json\n",
            "\u001b[38;5;2m✔ Generated README.md from meta.json\u001b[0m\n",
            "\u001b[38;5;2m✔ Successfully created package directory\n",
            "'en_ner_reddit_cooking-5.0.0'\u001b[0m\n",
            "packages/en_ner_reddit_cooking-5.0.0\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/en_ner_reddit_cooking\n",
            "copying en_ner_reddit_cooking/__init__.py -> build/lib/en_ner_reddit_cooking\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tokenizer -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/config.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/README.md -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/meta.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups/lookups.bin -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/moves -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler/patterns -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/moves -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/vectors -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/lookups.bin -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/strings.json -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/key2row -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/vectors.cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec\n",
            "creating build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger/cfg -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger\n",
            "copying en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger/model -> build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger\n",
            "copying en_ner_reddit_cooking/meta.json -> build/lib/en_ner_reddit_cooking\n",
            "/Users/ryan/Desktop/Desktop - Ryan’s iMac/teaching/dsba6188-homework-1/venv/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "installing to build/bdist.macosx-13-arm64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.macosx-13-arm64\n",
            "creating build/bdist.macosx-13-arm64/wheel\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups/lookups.bin -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/moves -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tokenizer -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler/patterns -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/moves -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/vectors -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/lookups.bin -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/strings.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/key2row -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/vectors.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/config.cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/README.md -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger/cfg -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger/model -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger\n",
            "copying build/lib/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0\n",
            "copying build/lib/en_ner_reddit_cooking/__init__.py -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "copying build/lib/en_ner_reddit_cooking/meta.json -> build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating en_ner_reddit_cooking.egg-info\n",
            "writing en_ner_reddit_cooking.egg-info/PKG-INFO\n",
            "writing dependency_links to en_ner_reddit_cooking.egg-info/dependency_links.txt\n",
            "writing entry points to en_ner_reddit_cooking.egg-info/entry_points.txt\n",
            "writing requirements to en_ner_reddit_cooking.egg-info/requires.txt\n",
            "writing top-level names to en_ner_reddit_cooking.egg-info/top_level.txt\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching 'LICENSES_SOURCES'\n",
            "writing manifest file 'en_ner_reddit_cooking.egg-info/SOURCES.txt'\n",
            "Copying en_ner_reddit_cooking.egg-info to build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-5.0.0-py3.9.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.macosx-13-arm64/wheel/en_ner_reddit_cooking-5.0.0.dist-info/WHEEL\n",
            "creating 'dist/en_ner_reddit_cooking-5.0.0-py3-none-any.whl' and adding 'build/bdist.macosx-13-arm64/wheel' to it\n",
            "adding 'en_ner_reddit_cooking/__init__.py'\n",
            "adding 'en_ner_reddit_cooking/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/README.md'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/config.cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/meta.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tokenizer'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/attribute_ruler/patterns'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/lemmatizer/lookups/lookups.bin'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/ner/moves'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/parser/moves'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tagger/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec/cfg'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/tok2vec/model'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/key2row'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/lookups.bin'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/strings.json'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/vectors'\n",
            "adding 'en_ner_reddit_cooking/en_ner_reddit_cooking-5.0.0/vocab/vectors.cfg'\n",
            "adding 'en_ner_reddit_cooking-5.0.0.dist-info/METADATA'\n",
            "adding 'en_ner_reddit_cooking-5.0.0.dist-info/WHEEL'\n",
            "adding 'en_ner_reddit_cooking-5.0.0.dist-info/entry_points.txt'\n",
            "adding 'en_ner_reddit_cooking-5.0.0.dist-info/top_level.txt'\n",
            "adding 'en_ner_reddit_cooking-5.0.0.dist-info/RECORD'\n",
            "removing build/bdist.macosx-13-arm64/wheel\n",
            "\u001b[38;5;2m✔ Successfully created binary wheel\u001b[0m\n",
            "packages/en_ner_reddit_cooking-5.0.0/dist/en_ner_reddit_cooking-5.0.0-py3-none-any.whl\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p packages\n",
        "!python -m spacy package ./output/experiment-1/model-best ./packages --name ner_reddit_cooking --version 1.0.0 --build wheel\n",
        "!python -m spacy package ./output/experiment-2/model-best ./packages --name ner_reddit_cooking --version 2.0.0 --build wheel\n",
        "!python -m spacy package ./output/experiment-3/model-best ./packages --name ner_reddit_cooking --version 3.0.0 --build wheel\n",
        "!python -m spacy package ./output/experiment-4/model-best ./packages --name ner_reddit_cooking --version 4.0.0 --build wheel\n",
        "!python -m spacy package ./output/experiment-5/model-best ./packages --name ner_reddit_cooking --version 5.0.0 --build wheel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2052d6a4",
      "metadata": {},
      "source": [
        "Let's now copy `cp` the files to the `models` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "6c93e099",
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p models\n",
        "!cp -n packages/en_ner_reddit_cooking-1.0.0/dist/en_ner_reddit_cooking-1.0.0-py3-none-any.whl models/en_ner_reddit_cooking-1.0.0-py3-none-any.whl\n",
        "!cp -n packages/en_ner_reddit_cooking-2.0.0/dist/en_ner_reddit_cooking-2.0.0-py3-none-any.whl models/en_ner_reddit_cooking-2.0.0-py3-none-any.whl\n",
        "!cp -n packages/en_ner_reddit_cooking-3.0.0/dist/en_ner_reddit_cooking-3.0.0-py3-none-any.whl models/en_ner_reddit_cooking-3.0.0-py3-none-any.whl\n",
        "!cp -n packages/en_ner_reddit_cooking-4.0.0/dist/en_ner_reddit_cooking-4.0.0-py3-none-any.whl models/en_ner_reddit_cooking-4.0.0-py3-none-any.whl\n",
        "!cp -n packages/en_ner_reddit_cooking-5.0.0/dist/en_ner_reddit_cooking-5.0.0-py3-none-any.whl models/en_ner_reddit_cooking-5.0.0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e01c495",
      "metadata": {},
      "source": [
        "This now means that you can install any of the models using `pip install` like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "e2d41b86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ./models/en_ner_reddit_cooking-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in ./venv/lib/python3.9/site-packages (from en-ner-reddit-cooking==5.0.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (69.0.3)\n",
            "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in ./venv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (1.26.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in ./venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./venv/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./venv/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./venv/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-ner-reddit-cooking==5.0.0) (2.1.5)\n",
            "Installing collected packages: en-ner-reddit-cooking\n",
            "Successfully installed en-ner-reddit-cooking-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install models/en_ner_reddit_cooking-5.0.0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7074cbec",
      "metadata": {},
      "source": [
        "Then you can use in Python to load that model like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "2a107528",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(mayo, plain yogurt, curry powder, mustard powder, mustard, ground coriander)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_ner_reddit_cooking\")\n",
        "doc = nlp(\"Make a dressing with mayo, plain yogurt, curry powder, mustard powder, mustard, ground coriander.\")\n",
        "doc.ents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ec9e1c",
      "metadata": {},
      "source": [
        "### Save models to HF Hub\n",
        "\n",
        "You can then save your model to Hugging Face Hub too. For this, you'll need to have installed `spacy-huggingface_hub`, which is in the `requirements.txt`. You'll also need a HF Hub/Spaces account and set up your API token (see [link](https://huggingface.co/settings/tokens))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acd55064",
      "metadata": {},
      "outputs": [],
      "source": [
        "!huggingface-cli login # recommend doing in terminal, not notebook\n",
        "!python -m spacy huggingface-hub push models/en_ner_reddit_cooking-5.0.0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c92050e",
      "metadata": {},
      "source": [
        "If it runs successfully, you should get a final message like:\n",
        "```\n",
        "View your model here:https://huggingface.co/wesslen/en_ner_reddit_cooking\n",
        "\n",
        "Install your model:\n",
        "pip install https://huggingface.co/wesslen/en_ner_reddit_cooking/resolve/main/en_ner_reddit_cooking-any-py3-none-any.whl\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d010118b",
      "metadata": {},
      "source": [
        "You can view and test my model here: https://huggingface.co/wesslen/en_ner_reddit_cooking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfd8fac",
      "metadata": {},
      "source": [
        "### Appendix: Drop files\n",
        "\n",
        "This is commented out and can be used to \"clean\" any Prodigy datasets and remove any models/packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a1a60571",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python -m prodigy drop hmwk_1_zeroshot\n",
        "# !python -m prodigy drop hmwk_1_workshop\n",
        "# !python -m prodigy drop hmwk_1_eval\n",
        "# !python -m prodigy drop hmwk_1_train_exp3\n",
        "# !python -m prodigy drop hmwk_1_train_exp4\n",
        "# !rm -rf output\n",
        "# !rm -rf packages"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
